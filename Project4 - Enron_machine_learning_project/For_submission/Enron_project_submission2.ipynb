{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Fraud from Enron Email\n",
    "**Machine Learning Project â€” Udacity Data Analyst Nanodegree**\n",
    "\n",
    "### Dataset Background\n",
    "In 2000, Enron was one of the largest companies in the United States. By 2002, it had collapsed into bankruptcy due to widespread corporate fraud. In the resulting Federal investigation, a significant amount of typically confidential information entered into the public record, including tens of thousands of emails and detailed financial data for top executives. This data comes with a hand-generated list of persons of interest in the fraud case, which means individuals who were indicted, reached a settlement or plea deal with the government, or testified in exchange for prosecution immunity. In this project, I will try my best to build a person of interest identifier based on financial and email data made public as a result of the Enron scandal.\n",
    "\n",
    "Below cell basically consists only of the provided starter code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rapha\\anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('C:/Users/Rapha/Documents/Datascience_Nanodegree/Projekte/Project4/For_submission')\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "sys.path.append('C:/Users/Rapha/Documents/Datascience_Nanodegree/Projekte/Project4/tools')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "import poi_plot, poi_explore\n",
    "\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "\n",
    "payment_data = ['salary',\n",
    "                'bonus',\n",
    "                'long_term_incentive',\n",
    "                'deferred_income',\n",
    "                'deferral_payments',\n",
    "                'loan_advances',\n",
    "                'other',\n",
    "                'expenses',                \n",
    "                'director_fees', \n",
    "                'total_payments',\n",
    "                'exercised_stock_options',\n",
    "                'restricted_stock',\n",
    "                'restricted_stock_deferred',\n",
    "                'total_stock_value']\n",
    "\n",
    "email_data = ['to_messages',\n",
    "              'from_messages',\n",
    "              'from_poi_to_this_person',\n",
    "              'from_this_person_to_poi',\n",
    "              'shared_receipt_with_poi']\n",
    "\n",
    "features_list = ['poi'] + payment_data + email_data # You will need to use more features\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "\n",
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The starter code will output the data in the form of a Python dictionary where each key-value pair corresponds to one person. The key is the person's name, and the value is another dictionary. \n",
    "\n",
    "For easier handling I will convert it to a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create new dataframe from dict\n",
    "df = pd.DataFrame.from_dict(data_dict, orient='index')\n",
    "#parse 'NaN' values as np.nan\n",
    "df = df.replace('NaN', np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a view on the size of our data we can either just call the general info or specifically query the number of persons and features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 146 entries, ALLEN PHILLIP K to YEAP SOON\n",
      "Data columns (total 21 columns):\n",
      "salary                       95 non-null float64\n",
      "to_messages                  86 non-null float64\n",
      "deferral_payments            39 non-null float64\n",
      "total_payments               125 non-null float64\n",
      "exercised_stock_options      102 non-null float64\n",
      "bonus                        82 non-null float64\n",
      "restricted_stock             110 non-null float64\n",
      "shared_receipt_with_poi      86 non-null float64\n",
      "restricted_stock_deferred    18 non-null float64\n",
      "total_stock_value            126 non-null float64\n",
      "expenses                     95 non-null float64\n",
      "loan_advances                4 non-null float64\n",
      "from_messages                86 non-null float64\n",
      "other                        93 non-null float64\n",
      "from_this_person_to_poi      86 non-null float64\n",
      "poi                          146 non-null bool\n",
      "director_fees                17 non-null float64\n",
      "deferred_income              49 non-null float64\n",
      "long_term_incentive          66 non-null float64\n",
      "email_address                111 non-null object\n",
      "from_poi_to_this_person      86 non-null float64\n",
      "dtypes: bool(1), float64(19), object(1)\n",
      "memory usage: 24.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the info query I can see that all values are parsed in floating point format except from \"email_address\" and \"POI\", with the latter being a boolean.\n",
    "\n",
    "In addition to that one can notice that the dataset contains many missing 'null'/'nan' values. In the next chapter I will elaborate on how to interpret and treat these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people in the Enron dataset: 146\n",
      "Number of features for each person in the Enron dataset: 21\n"
     ]
    }
   ],
   "source": [
    "print 'Number of people in the Enron dataset: {0}'.format(len(df))\n",
    "print 'Number of features for each person in the Enron dataset: {0}'.format(len(df.iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 146 rows in the dataset which correspond to 146 individuals and 21 features.\n",
    "\n",
    "By overwriting the dataframe with only the features list I deliberately disregard the column \"email_address\" since this will not be of value. After that we will be left with 20 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[features_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features for each person in the Enron dataset: 20\n"
     ]
    }
   ],
   "source": [
    "print 'Number of features for each person in the Enron dataset: {0}'.format(len(df.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of POI's: 18\n"
     ]
    }
   ],
   "source": [
    "pois = df['poi'].loc[df['poi'] == True]\n",
    "print 'Number of POI\\'s: {0}'.format(len(pois))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN Value Treatment\n",
    "\n",
    "Taking a look into the original Pdf-file for the financial data my interpretation is that empty fields do not stand for unknown quantities but represent \"0\". However for the e-mail data NaNs are unknown information. \n",
    "\n",
    "For that reason I will replace any financial data which is NaN with a \"0\" whereas for the e-mail data I will replace NaN values with the mean of the respective column grouped by POIs and Non-POIS. In other words if a NaN-value corresponds to a POI it will be filled with the mean of the POIs in that column and if a NaN value correspsonds to a Non-POI it will be filled with the mean of the Non-POIs in that column. If I chose to drop all NaNs it would reduce the size of what is already a small dataset. Since the perfomance of a machine learning algorithm is proportional to the amount of data fed into it, I am hesitant to remove any information that could possibly be of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "poi                            0\n",
       "salary                        51\n",
       "bonus                         64\n",
       "long_term_incentive           80\n",
       "deferred_income               97\n",
       "deferral_payments            107\n",
       "loan_advances                142\n",
       "other                         53\n",
       "expenses                      51\n",
       "director_fees                129\n",
       "total_payments                21\n",
       "exercised_stock_options       44\n",
       "restricted_stock              36\n",
       "restricted_stock_deferred    128\n",
       "total_stock_value             20\n",
       "to_messages                   60\n",
       "from_messages                 60\n",
       "from_poi_to_this_person       60\n",
       "from_this_person_to_poi       60\n",
       "shared_receipt_with_poi       60\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the NaN payment and stock values with zero \n",
    "df[payment_data] = df[payment_data].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rapha\\anaconda3\\envs\\python2\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# Fill in the NaN email data with the mean of column grouped by poi/ non_poi\n",
    "imp = Imputer(missing_values='NaN', strategy = 'mean', axis=0)\n",
    "\n",
    "df_poi = df[df['poi'] == True];\n",
    "df_nonpoi = df[df['poi']==False]\n",
    "\n",
    "df_poi.loc[:, email_data] = imp.fit_transform(df_poi.loc[:,email_data]);\n",
    "df_nonpoi.loc[:, email_data] = imp.fit_transform(df_nonpoi.loc[:,email_data]);\n",
    "df = df_poi.append(df_nonpoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "poi                          0\n",
       "salary                       0\n",
       "bonus                        0\n",
       "long_term_incentive          0\n",
       "deferred_income              0\n",
       "deferral_payments            0\n",
       "loan_advances                0\n",
       "other                        0\n",
       "expenses                     0\n",
       "director_fees                0\n",
       "total_payments               0\n",
       "exercised_stock_options      0\n",
       "restricted_stock             0\n",
       "restricted_stock_deferred    0\n",
       "total_stock_value            0\n",
       "to_messages                  0\n",
       "from_messages                0\n",
       "from_poi_to_this_person      0\n",
       "from_this_person_to_poi      0\n",
       "shared_receipt_with_poi      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>bonus</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>other</th>\n",
       "      <th>expenses</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>146.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.658114e+05</td>\n",
       "      <td>1.333474e+06</td>\n",
       "      <td>6.646839e+05</td>\n",
       "      <td>-3.827622e+05</td>\n",
       "      <td>4.387965e+05</td>\n",
       "      <td>1.149658e+06</td>\n",
       "      <td>5.854318e+05</td>\n",
       "      <td>7.074827e+04</td>\n",
       "      <td>1.942249e+04</td>\n",
       "      <td>4.350622e+06</td>\n",
       "      <td>4.182736e+06</td>\n",
       "      <td>1.749257e+06</td>\n",
       "      <td>2.051637e+04</td>\n",
       "      <td>5.846018e+06</td>\n",
       "      <td>2057.662970</td>\n",
       "      <td>623.343879</td>\n",
       "      <td>63.343444</td>\n",
       "      <td>40.030224</td>\n",
       "      <td>1147.846271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.203575e+06</td>\n",
       "      <td>8.094029e+06</td>\n",
       "      <td>4.046072e+06</td>\n",
       "      <td>2.378250e+06</td>\n",
       "      <td>2.741325e+06</td>\n",
       "      <td>9.649342e+06</td>\n",
       "      <td>3.682345e+06</td>\n",
       "      <td>4.327163e+05</td>\n",
       "      <td>1.190543e+05</td>\n",
       "      <td>2.693448e+07</td>\n",
       "      <td>2.607040e+07</td>\n",
       "      <td>1.089995e+07</td>\n",
       "      <td>1.439661e+06</td>\n",
       "      <td>3.624681e+07</td>\n",
       "      <td>1978.612966</td>\n",
       "      <td>1410.919321</td>\n",
       "      <td>66.918580</td>\n",
       "      <td>76.789203</td>\n",
       "      <td>910.277086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.799289e+07</td>\n",
       "      <td>-1.025000e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.604490e+06</td>\n",
       "      <td>-7.576788e+06</td>\n",
       "      <td>-4.409300e+04</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.792600e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.394475e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.115000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.288695e+05</td>\n",
       "      <td>904.250000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>591.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.105960e+05</td>\n",
       "      <td>3.000000e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.595000e+02</td>\n",
       "      <td>2.018200e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.413595e+05</td>\n",
       "      <td>6.082935e+05</td>\n",
       "      <td>3.605280e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.659550e+05</td>\n",
       "      <td>2007.111111</td>\n",
       "      <td>392.178571</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>36.277778</td>\n",
       "      <td>1058.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.708505e+05</td>\n",
       "      <td>8.000000e+05</td>\n",
       "      <td>3.750648e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.684500e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.506065e+05</td>\n",
       "      <td>5.374075e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.968287e+06</td>\n",
       "      <td>1.714221e+06</td>\n",
       "      <td>8.145280e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.319991e+06</td>\n",
       "      <td>2007.111111</td>\n",
       "      <td>668.763889</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>36.277778</td>\n",
       "      <td>1117.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.670423e+07</td>\n",
       "      <td>9.734362e+07</td>\n",
       "      <td>4.852193e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.208340e+07</td>\n",
       "      <td>8.392500e+07</td>\n",
       "      <td>4.266759e+07</td>\n",
       "      <td>5.235198e+06</td>\n",
       "      <td>1.398517e+06</td>\n",
       "      <td>3.098866e+08</td>\n",
       "      <td>3.117640e+08</td>\n",
       "      <td>1.303223e+08</td>\n",
       "      <td>1.545629e+07</td>\n",
       "      <td>4.345095e+08</td>\n",
       "      <td>15149.000000</td>\n",
       "      <td>14368.000000</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>5521.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             salary         bonus  long_term_incentive  deferred_income  \\\n",
       "count  1.460000e+02  1.460000e+02         1.460000e+02     1.460000e+02   \n",
       "mean   3.658114e+05  1.333474e+06         6.646839e+05    -3.827622e+05   \n",
       "std    2.203575e+06  8.094029e+06         4.046072e+06     2.378250e+06   \n",
       "min    0.000000e+00  0.000000e+00         0.000000e+00    -2.799289e+07   \n",
       "25%    0.000000e+00  0.000000e+00         0.000000e+00    -3.792600e+04   \n",
       "50%    2.105960e+05  3.000000e+05         0.000000e+00     0.000000e+00   \n",
       "75%    2.708505e+05  8.000000e+05         3.750648e+05     0.000000e+00   \n",
       "max    2.670423e+07  9.734362e+07         4.852193e+07     0.000000e+00   \n",
       "\n",
       "       deferral_payments  loan_advances         other      expenses  \\\n",
       "count       1.460000e+02   1.460000e+02  1.460000e+02  1.460000e+02   \n",
       "mean        4.387965e+05   1.149658e+06  5.854318e+05  7.074827e+04   \n",
       "std         2.741325e+06   9.649342e+06  3.682345e+06  4.327163e+05   \n",
       "min        -1.025000e+05   0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%         0.000000e+00   0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%         0.000000e+00   0.000000e+00  9.595000e+02  2.018200e+04   \n",
       "75%         9.684500e+03   0.000000e+00  1.506065e+05  5.374075e+04   \n",
       "max         3.208340e+07   8.392500e+07  4.266759e+07  5.235198e+06   \n",
       "\n",
       "       director_fees  total_payments  exercised_stock_options  \\\n",
       "count   1.460000e+02    1.460000e+02             1.460000e+02   \n",
       "mean    1.942249e+04    4.350622e+06             4.182736e+06   \n",
       "std     1.190543e+05    2.693448e+07             2.607040e+07   \n",
       "min     0.000000e+00    0.000000e+00             0.000000e+00   \n",
       "25%     0.000000e+00    9.394475e+04             0.000000e+00   \n",
       "50%     0.000000e+00    9.413595e+05             6.082935e+05   \n",
       "75%     0.000000e+00    1.968287e+06             1.714221e+06   \n",
       "max     1.398517e+06    3.098866e+08             3.117640e+08   \n",
       "\n",
       "       restricted_stock  restricted_stock_deferred  total_stock_value  \\\n",
       "count      1.460000e+02               1.460000e+02       1.460000e+02   \n",
       "mean       1.749257e+06               2.051637e+04       5.846018e+06   \n",
       "std        1.089995e+07               1.439661e+06       3.624681e+07   \n",
       "min       -2.604490e+06              -7.576788e+06      -4.409300e+04   \n",
       "25%        8.115000e+03               0.000000e+00       2.288695e+05   \n",
       "50%        3.605280e+05               0.000000e+00       9.659550e+05   \n",
       "75%        8.145280e+05               0.000000e+00       2.319991e+06   \n",
       "max        1.303223e+08               1.545629e+07       4.345095e+08   \n",
       "\n",
       "        to_messages  from_messages  from_poi_to_this_person  \\\n",
       "count    146.000000     146.000000               146.000000   \n",
       "mean    2057.662970     623.343879                63.343444   \n",
       "std     1978.612966    1410.919321                66.918580   \n",
       "min       57.000000      12.000000                 0.000000   \n",
       "25%      904.250000      36.000000                25.750000   \n",
       "50%     2007.111111     392.178571                58.500000   \n",
       "75%     2007.111111     668.763889                58.500000   \n",
       "max    15149.000000   14368.000000               528.000000   \n",
       "\n",
       "       from_this_person_to_poi  shared_receipt_with_poi  \n",
       "count               146.000000               146.000000  \n",
       "mean                 40.030224              1147.846271  \n",
       "std                  76.789203               910.277086  \n",
       "min                   0.000000                 2.000000  \n",
       "25%                   6.000000               591.500000  \n",
       "50%                  36.277778              1058.527778  \n",
       "75%                  36.277778              1117.500000  \n",
       "max                 609.000000              5521.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for errors in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a validity check errors in the financial data by adding up all payment data for each person and check if this equals the total payment for that person. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poi</th>\n",
       "      <th>salary</th>\n",
       "      <th>bonus</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>other</th>\n",
       "      <th>expenses</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BELFER ROBERT</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-102500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>102500.0</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44093.0</td>\n",
       "      <td>-44093.0</td>\n",
       "      <td>2007.111111</td>\n",
       "      <td>668.763889</td>\n",
       "      <td>58.5</td>\n",
       "      <td>36.277778</td>\n",
       "      <td>1058.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BHATNAGAR SANJAY</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137864.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137864.0</td>\n",
       "      <td>15456290.0</td>\n",
       "      <td>2604490.0</td>\n",
       "      <td>-2604490.0</td>\n",
       "      <td>15456290.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>523.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>463.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    poi  salary  bonus  long_term_incentive  deferred_income  \\\n",
       "BELFER ROBERT     False     0.0    0.0                  0.0              0.0   \n",
       "BHATNAGAR SANJAY  False     0.0    0.0                  0.0              0.0   \n",
       "\n",
       "                  deferral_payments  loan_advances     other  expenses  \\\n",
       "BELFER ROBERT             -102500.0            0.0       0.0       0.0   \n",
       "BHATNAGAR SANJAY                0.0            0.0  137864.0       0.0   \n",
       "\n",
       "                  director_fees  total_payments  exercised_stock_options  \\\n",
       "BELFER ROBERT            3285.0        102500.0                   3285.0   \n",
       "BHATNAGAR SANJAY       137864.0      15456290.0                2604490.0   \n",
       "\n",
       "                  restricted_stock  restricted_stock_deferred  \\\n",
       "BELFER ROBERT                  0.0                    44093.0   \n",
       "BHATNAGAR SANJAY        -2604490.0                 15456290.0   \n",
       "\n",
       "                  total_stock_value  to_messages  from_messages  \\\n",
       "BELFER ROBERT              -44093.0  2007.111111     668.763889   \n",
       "BHATNAGAR SANJAY                0.0   523.000000      29.000000   \n",
       "\n",
       "                  from_poi_to_this_person  from_this_person_to_poi  \\\n",
       "BELFER ROBERT                        58.5                36.277778   \n",
       "BHATNAGAR SANJAY                      0.0                 1.000000   \n",
       "\n",
       "                  shared_receipt_with_poi  \n",
       "BELFER ROBERT                 1058.527778  \n",
       "BHATNAGAR SANJAY               463.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross-check by adding up all of payment related columns\n",
    "errors_payment = (df[df[payment_data[:-5]].sum(axis='columns') != df['total_payments']])\n",
    "errors_payment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed there are two individuals for which the sum of their payment data does not add up to the alleged total payment. The errors are already present in the original Pdf-File and seem to be caused by a misalignment between the columns. For Robert Belfer the financial data has been shifted one column to the right, whereas for Sanjay Bhatnagar the data has been shifted one column to the left. I will fix that issue by shifting the columns and then check again if the payment data add up correctly to the respective \"total_payment\" and \"total_stock_value\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the incorrect data for Belfer\n",
    "belfer_financial = df.loc['BELFER ROBERT','salary':'total_stock_value'].tolist()\n",
    "# Delete the first element to shift left and add on a 0 to end as indicated in financial data\n",
    "belfer_financial.pop(0)\n",
    "belfer_financial.append(0.)\n",
    "# Reinsert corrected data\n",
    "df.loc['BELFER ROBERT','salary':'total_stock_value'] = belfer_financial\n",
    "\n",
    "# Retrieve the incorrect data for Bhatnagar\n",
    "bhatnagar_financial = df.loc['BHATNAGAR SANJAY','salary':'total_stock_value'].tolist()\n",
    "# Delete the last element to shift right and add on a 0 to beginning\n",
    "bhatnagar_financial.pop(-1)\n",
    "bhatnagar_financial = [0] + bhatnagar_financial\n",
    "# Reinsert corrected data\n",
    "df.loc['BHATNAGAR SANJAY','salary':'total_stock_value'] = bhatnagar_financial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poi</th>\n",
       "      <th>salary</th>\n",
       "      <th>bonus</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>other</th>\n",
       "      <th>expenses</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [poi, salary, bonus, long_term_incentive, deferred_income, deferral_payments, loan_advances, other, expenses, director_fees, total_payments, exercised_stock_options, restricted_stock, restricted_stock_deferred, total_stock_value, to_messages, from_messages, from_poi_to_this_person, from_this_person_to_poi, shared_receipt_with_poi]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if errors in payment data are solved\n",
    "df[df[payment_data[:-5]].sum(axis='columns') != df['total_payments']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poi</th>\n",
       "      <th>salary</th>\n",
       "      <th>bonus</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>other</th>\n",
       "      <th>expenses</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [poi, salary, bonus, long_term_incentive, deferred_income, deferral_payments, loan_advances, other, expenses, director_fees, total_payments, exercised_stock_options, restricted_stock, restricted_stock_deferred, total_stock_value, to_messages, from_messages, from_poi_to_this_person, from_this_person_to_poi, shared_receipt_with_poi]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if errors in stock data are solved\n",
    "df[df[payment_data[10:-1]].sum(axis='columns') != df['total_stock_value']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I was screening the Pdf-file more closely I stumbled upon an individual called \"THE TRAVEL AGENCY IN THE PARK\". Obviously this is not the name of an employee but according to documentation was a company owned by Enron's former Chairman's sister and is therefore clearly not a data point which should be included in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(axis=0, labels=['THE TRAVEL AGENCY IN THE PARK'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outlier explorations starts by plotting two of the most telling features when it comes to uncover the relation between the data and POIs: Salary & Bonus\n",
    "\n",
    "To be able to reuse the scatterplot-code from the Udacity lessons, first I will have to convert the dataframe back to a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = df.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Scatterplot of Salary vs. Bonus*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "poi_plot.scatterplot(my_dataset, \"salary\", \"bonus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier name: TOTAL\n"
     ]
    }
   ],
   "source": [
    "# Find the outlier with the highest salary\n",
    "outlier = poi_explore.sort_data(my_dataset, \"salary\", 1, reverse=True)\n",
    "outlier_name = poi_explore.get_name(my_dataset, \"salary\", outlier[0])\n",
    "print 'Outlier name: {0}'.format(outlier_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot clearly shows an outlier in the top right of the plot. Ordering the list by salary, the outlier is called \"TOTAL\", which represents the sum of all the salaries as shown in the Pdf. Since this entry does not represent a person it is invalid and is therefore removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outlier TOTAL from dict and from df\n",
    "my_dataset.pop('TOTAL', None);\n",
    "df.drop(axis=0, labels=['TOTAL'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatterplot of Salary vs. Bonus of original dataset after removal of outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "poi_plot.scatterplot(my_dataset, \"salary\", \"bonus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "144\n"
     ]
    }
   ],
   "source": [
    "#Entries in Dict & Dataframe after Cleaning and outlier removal\n",
    "print (len(my_dataset))\n",
    "print (len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning and outlier removal the data set is left with 144 entries that all represent valid Enron employees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick Algorithms and first shot performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first training and testing runs will be to assess the out-of-the-box performance of several algorithms using all of the 20 features. For this initial step I selected 6 algorithms: GaussianNB, DecisionTreeClassifier, SVC, KMeans, AdaBoostClassifier and RandomForestClassifier. \n",
    "\n",
    "I will run the algorithms with the default parameters except I will alter the kernel used in the Support Vector Machine to be linear and I will select the number of clusters = 2 for KMeans as I know in advance that the targets are only two categories that should be classified.\n",
    "\n",
    "Concerning algorithm performance I will base my assessment on the F1-score. Since the F1-score is a combined measure of precision and recall I think it will serve best our aim to achieve both a good Recall and Precision. For this project the minimum requirement is a precision and recall score of at least 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "\tAccuracy: 0.77220\tPrecision: 0.25991\tRecall: 0.38350\tF1: 0.30984\tF2: 0.35020\n",
      "\tTotal predictions: 15000\tTrue positives:  767\tFalse positives: 2184\tFalse negatives: 1233\tTrue negatives: 10816\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import tester\n",
    "\n",
    "# Create and test the Gaussian Naive Bayes Classifier\n",
    "clf = GaussianNB()\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "tester.main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "\tAccuracy: 0.81547\tPrecision: 0.31538\tRecall: 0.32800\tF1: 0.32157\tF2: 0.32540\n",
      "\tTotal predictions: 15000\tTrue positives:  656\tFalse positives: 1424\tFalse negatives: 1344\tTrue negatives: 11576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and test the Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "tester.main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rapha\\anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\svm\\base.py:220: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=1000, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\tAccuracy: 0.48540\tPrecision: 0.14027\tRecall: 0.55750\tF1: 0.22414\tF2: 0.34955\n",
      "\tTotal predictions: 15000\tTrue positives: 1115\tFalse positives: 6834\tFalse negatives:  885\tTrue negatives: 6166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and test the Support Vector Classifier\n",
    "clf = SVC(kernel='linear', max_iter=1000)\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "tester.main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=0)\n",
      "\tAccuracy: 0.82960\tPrecision: 0.20921\tRecall: 0.10000\tF1: 0.13532\tF2: 0.11166\n",
      "\tTotal predictions: 15000\tTrue positives:  200\tFalse positives:  756\tFalse negatives: 1800\tTrue negatives: 12244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and test the K Means clustering classifier\n",
    "clf = KMeans(n_clusters=2)\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "tester.main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "\tAccuracy: 0.86307\tPrecision: 0.48133\tRecall: 0.34800\tF1: 0.40395\tF2: 0.36841\n",
      "\tTotal predictions: 15000\tTrue positives:  696\tFalse positives:  750\tFalse negatives: 1304\tTrue negatives: 12250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and test the AdaBoost classifier\n",
    "clf = AdaBoostClassifier()\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "tester.main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.86987\tPrecision: 0.53715\tRecall: 0.17350\tF1: 0.26228\tF2: 0.20067\n",
      "\tTotal predictions: 15000\tTrue positives:  347\tFalse positives:  299\tFalse negatives: 1653\tTrue negatives: 12701\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and test the RandomForest classifier\n",
    "clf = RandomForestClassifier()\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "tester.main();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both GaussianNB and DecisionTreeClassifier achieved a good result in F1-score even exceeding the required 0.3 just out-of-the-box. Also AdaBoostClassifier did a decent job. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation\n",
    "By making use of the tester.py script provided from Udacity I could run these training and testing runs with minimal code here. What the tester.py script does, it uses StatifiedShuffleSPlit to split the data into labels and features sets with which the classifier is being trained and tested and then randomly shuffles the data before splitting it again into training and testing sets. This process is being repeated several times. In our case 1000 times since this is the value provided in the tester.py script. This iterative shuffling and splitting is one possible form of what is being referred to as cross-validation. \n",
    "\n",
    "Cross-validation prevents one from making the classic mistake of training an algoithm on the same data used to test the algorithm. If this happens, the test results may show that the classifier is accurate, but that is only because the algorithm has seen the testing data before. When the classifier is deployed on new samples, the performance may be poor because it was trained and tuned for a very specific set of instances. The classifier will not be able to generalize to new cases because it is only fit and tuned to the specific samples it is tested on. Cross-validation solves this issue by training and testing on multiple different subsets of the features and labels and is ideal for use on small datasets to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling of some sort whether that is Normalization (MinMax scaling) or Standardization is usually necessary because there are different units for the features in the dataset. Scaling creates non-dimensional features such that those features with a larger range of values do not have an undue influence on the classifier. For example, many classifiers calculate the distance between two points by the Euclidean distance. If one of the features has a broad range of values, the distance will be governed by this particular feature. Therefore, the range of all features should be normalized so that each feature contributes approximately proportionately to the final distance.\n",
    "\n",
    "In the following I will test if feature scaling has a positive effect on the overall algorithm performance. This is not required as per project specifications but rather I will do this out of curiosity. Instead I could have just applied scaling only for algorithms that utilize Euclidian distances which is how one would usually handle it (will be explained at the end of chapter scaling).\n",
    "\n",
    "I will run the algorithms as I did before only this time with standardized values. Feature standardization makes the values of each feature in the data have zero-mean and unit-variance. Sklearn's preprocessing module provides a scale function which I will use to generate a new dataset with scaled values.\n",
    "\n",
    "There is also another method from Scikitlearn called 'StandardScaler' which according to the docs is actually the preferred method. The problem with scaling a dataset before splitting it into training and testing sets is that it will bias the model evaluation because information would have leaked from the test set into the training set. This is a common mistake which is why the use of StandardScaler is recommended. In the following I will try both so I can make a cross check between the two methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rapha\\anaconda3\\envs\\python2\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Scale the dataset and send it back to a dictionary\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "scaled_df = df.copy()\n",
    "scaled_df.ix[:,1:] = scale(scaled_df.ix[:,1:])\n",
    "my_dataset_scaled = scaled_df.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "\tAccuracy: 0.40013\tPrecision: 0.16003\tRecall: 0.82350\tF1: 0.26798\tF2: 0.45020\n",
      "\tTotal predictions: 15000\tTrue positives: 1647\tFalse positives: 8645\tFalse negatives:  353\tTrue negatives: 4355\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and test the Gaussian Naive Bayes Classifier with scaled data\n",
    "clf = GaussianNB()\n",
    "tester.dump_classifier_and_data(clf, my_dataset_scaled, features_list)\n",
    "tester.main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classify', GaussianNB(priors=None))])\n",
      "\tAccuracy: 0.39780\tPrecision: 0.15981\tRecall: 0.82600\tF1: 0.26781\tF2: 0.45046\n",
      "\tTotal predictions: 15000\tTrue positives: 1652\tFalse positives: 8685\tFalse negatives:  348\tTrue negatives: 4315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crosscheck with StandardScaler in a pipeline\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "clf = Pipeline([('scaler', StandardScaler()),('classify', GaussianNB())])\n",
    "\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "tester.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 'Standard Scaler' within a Pipeline produces nearly the same results. Therefore I conclude that both methods produce valid results. I assume it will be the case also for the other classifiers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "\tAccuracy: 0.81593\tPrecision: 0.32060\tRecall: 0.34000\tF1: 0.33002\tF2: 0.33594\n",
      "\tTotal predictions: 15000\tTrue positives:  680\tFalse positives: 1441\tFalse negatives: 1320\tTrue negatives: 11559\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and test the Decision Tree Classifier with scaled data\n",
    "clf = DecisionTreeClassifier()\n",
    "tester.dump_classifier_and_data(clf, my_dataset_scaled, features_list)\n",
    "tester.main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=1000, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\tAccuracy: 0.87080\tPrecision: 0.54247\tRecall: 0.19800\tF1: 0.29011\tF2: 0.22680\n",
      "\tTotal predictions: 15000\tTrue positives:  396\tFalse positives:  334\tFalse negatives: 1604\tTrue negatives: 12666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and test the Support Vector Classifier with scaled data\n",
    "clf = SVC(kernel='linear', max_iter=1000)\n",
    "tester.dump_classifier_and_data(clf, my_dataset_scaled, features_list)\n",
    "tester.main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=0)\n",
      "\tAccuracy: 0.80860\tPrecision: 0.15464\tRecall: 0.09750\tF1: 0.11960\tF2: 0.10528\n",
      "\tTotal predictions: 15000\tTrue positives:  195\tFalse positives: 1066\tFalse negatives: 1805\tTrue negatives: 11934\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and test the K Means clustering classifier with scaled data\n",
    "clf = KMeans(n_clusters=2)\n",
    "tester.dump_classifier_and_data(clf, my_dataset_scaled, features_list)\n",
    "tester.main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "\tAccuracy: 0.86327\tPrecision: 0.48233\tRecall: 0.34800\tF1: 0.40430\tF2: 0.36853\n",
      "\tTotal predictions: 15000\tTrue positives:  696\tFalse positives:  747\tFalse negatives: 1304\tTrue negatives: 12253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and test the AdaBoost classifier with scaled data\n",
    "clf = AdaBoostClassifier()\n",
    "tester.dump_classifier_and_data(clf, my_dataset_scaled, features_list)\n",
    "tester.main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.86927\tPrecision: 0.53033\tRecall: 0.17050\tF1: 0.25804\tF2: 0.19727\n",
      "\tTotal predictions: 15000\tTrue positives:  341\tFalse positives:  302\tFalse negatives: 1659\tTrue negatives: 12698\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and test the RandomForest classifier with scaled data\n",
    "clf = RandomForestClassifier()\n",
    "tester.dump_classifier_and_data(clf, my_dataset_scaled, features_list)\n",
    "tester.main();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results from first shots\n",
    "Unscaled:\n",
    "\n",
    "| Classifier            | Accuracy | Precision | Recall  | F1 Score |\n",
    "|-----------------------|----------|-----------|---------|----------|\n",
    "| GaussianNB            | 0.772    | 0.260     | 0.384   | 0.310    |\n",
    "| DecisionTree          | 0.815    | 0.315     | 0.328   | 0.322    |\n",
    "| SVC (kernel='linear') | 0.485    | 0.140     | 0.558   | 0.224    |\n",
    "| KMeans (n_clusters=2) | 0.829    | 0.209     | 0.100   | 0.135    |\n",
    "| Adaboost              | 0.863    | 0.481     | 0.348   | 0.404    |\n",
    "| Random Forest         | 0.870    | 0.537     | 0.174   | 0.262    |\n",
    "\n",
    "Scaled:\n",
    "\n",
    "| Classifier            | Accuracy | Precision | Recall  | F1 Score |\n",
    "|-----------------------|----------|-----------|---------|----------|\n",
    "| GaussianNB            | 0.400    | 0.160     | 0.824   | 0.268    |\n",
    "| DecisionTree          | 0.816    | 0.321     | 0.340   | 0.330    |\n",
    "| SVC (kernel='linear') | 0.871    | 0.542     | 0.198   | 0.290    |\n",
    "| KMeans (n_clusters=2) | 0.809    | 0.154     | 0.098   | 0.120    |\n",
    "| Adaboost              | 0.863    | 0.482     | 0.348   | 0.404    |\n",
    "| Random Forest         | 0.869    | 0.530     | 0.171   | 0.258    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are mixed. For GaussianNB and DecisionTree the scaled data does not bring an improvement whereas for SVC the performance improved considerably. The performances of Random Forest and KMeans improved a little. AdaBoosts' performance did not change at all.\n",
    "\n",
    "In a way these results confirm kind of what one would already expect. Algorithms where feature scaling matters are ones that utilize Euclidean distances, like K-means or K-nearest neighbors, logistic regression, SVMs, perceptrons, neural networks, etc. For ensemble algorithms like AdaBoost, XGBoost, etc. they depend on the base_classifier. In Sklearn it uses DecisionTree by default thus scaling isn't needed. The DecisionTree itself does not utilize Euclidian distances either.\n",
    "\n",
    "However one may have expected a visible performance improvement for the KMeans-Algorithm. This I could not observe.\n",
    "\n",
    "The fact that RandomForest has improved in performance by a minimal fraction is not reason enough for me to apply scaling. Since RF is an ensemble algorithm it normally doens not require scaling. So I won't do it either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of feature engineering is to increase algorithm performance by creating new features out of existing information. In this case I try to combine existing features with each other in such way that it has a positive effect on the algorithms performance. \n",
    "\n",
    "For example the ratios between the email features 'from_poi_to_this_person' and 'to_messages' or 'from_messages' might be a useful combination for the creation of a new feature as it could be the case that somebody went unnoticed with lower email volume, but almost all of it directed to or coming from a POI. I could imagine that in contrast to total numbers these new features based on the percentage of emails to or from POIs will do a better job in revealing the persons with higher communication to POIs. It seems evident that individuals who interact more with a POI are themselves more likely to be a POI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the new email features to the dataframe\n",
    "df['to_poi_ratio'] = df['from_poi_to_this_person'] / df['to_messages']\n",
    "df['from_poi_ratio'] = df['from_this_person_to_poi'] / df['from_messages']\n",
    "\n",
    "features_list.append('to_poi_ratio')\n",
    "features_list.append('from_poi_ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition I will create two new financial features that are also a combination from already existing features. Namely the fraction of bonus&salary and bonus&total_payments. The reason for choosing these combinations are primarily because I suspect that persons receiving very large bonuses compared to their usual annual income are more likely to be involved in fraudulent activities and therefore be POIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the new financial features to the dataframe\n",
    "df['bonus_to_salary'] = df['bonus'] / df['salary']\n",
    "df['bonus_to_total'] = df['bonus'] / df['total_payments']\n",
    "\n",
    "features_list.append('bonus_to_salary')\n",
    "features_list.append('bonus_to_total')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features with newly engineered features: 24\n"
     ]
    }
   ],
   "source": [
    "print 'Number of features with newly engineered features: {0}'.format(len(df.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fill any NaN financial data with a 0\n",
    "df.fillna(value= 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = df.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rapha\\anaconda3\\envs\\python2\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#update 'scaled_df', and 'my_dataset_scaled' with new enineered features\n",
    "scaled_df = df.copy()\n",
    "scaled_df.ix[:,1:] = scale(scaled_df.ix[:,1:])\n",
    "\n",
    "my_dataset_scaled = scaled_df.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are now a total number of 24 features of which I do not yet know if I produced some unnecessary redundancies.\n",
    "Let's test the performances using the tester.py script and see if the newly engineered features bring some improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "\tAccuracy: 0.77220\tPrecision: 0.25991\tRecall: 0.38350\tF1: 0.30984\tF2: 0.35020\n",
      "\tTotal predictions: 15000\tTrue positives:  767\tFalse positives: 2184\tFalse negatives: 1233\tTrue negatives: 10816\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "tester.main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "\tAccuracy: 0.89847\tPrecision: 0.61955\tRecall: 0.61800\tF1: 0.61877\tF2: 0.61831\n",
      "\tTotal predictions: 15000\tTrue positives: 1236\tFalse positives:  759\tFalse negatives:  764\tTrue negatives: 12241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "tester.main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=1000, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\tAccuracy: 0.85960\tPrecision: 0.44894\tRecall: 0.23300\tF1: 0.30678\tF2: 0.25780\n",
      "\tTotal predictions: 15000\tTrue positives:  466\tFalse positives:  572\tFalse negatives: 1534\tTrue negatives: 12428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='linear', max_iter=1000)\n",
    "tester.dump_classifier_and_data(clf, my_dataset_scaled, features_list)\n",
    "tester.main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=0)\n",
      "\tAccuracy: 0.83047\tPrecision: 0.21807\tRecall: 0.10500\tF1: 0.14175\tF2: 0.11715\n",
      "\tTotal predictions: 15000\tTrue positives:  210\tFalse positives:  753\tFalse negatives: 1790\tTrue negatives: 12247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = KMeans(n_clusters=2)\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "tester.main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "\tAccuracy: 0.88000\tPrecision: 0.56068\tRecall: 0.46200\tF1: 0.50658\tF2: 0.47886\n",
      "\tTotal predictions: 15000\tTrue positives:  924\tFalse positives:  724\tFalse negatives: 1076\tTrue negatives: 12276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier()\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "tester.main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.88073\tPrecision: 0.63937\tRecall: 0.24200\tF1: 0.35111\tF2: 0.27635\n",
      "\tTotal predictions: 15000\tTrue positives:  484\tFalse positives:  273\tFalse negatives: 1516\tTrue negatives: 12727\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "tester.dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "tester.main();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After adding the new features, the scores for all algorithms have improved or at least remained the same.\n",
    "KMeans still performes very poorly regarding F1-score and recall so I will drop it for further investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results with engineered features\n",
    "Unscaled:\n",
    "\n",
    "| Classifier            | Accuracy | Precision | Recall  | F1 Score |\n",
    "|-----------------------|----------|-----------|---------|----------|\n",
    "| GaussianNB            | 0.772    | 0.260     | 0.384   | 0.310    |\n",
    "| DecisionTree          | 0.898    | 0.620     | 0.618   | 0.619    |\n",
    "| SVC (kernel='linear') | 0.860    | 0.449     | 0.233   | 0.307    |\n",
    "| KMeans (n_clusters=2) | 0.837    | 0.219     | 0.088   | 0.126    |\n",
    "| Adaboost              | 0.880    | 0.561     | 0.462   | 0.507    |\n",
    "| Random Forest         | 0.881    | 0.639     | 0.242   | 0.351    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the F1-score the DecisionTree is now leading the pack followed by AdaBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With overall 24 features this is quite a number. By creating new features I was able to improve performance but I do not yet know if all of the features are really necessary or if I can remove some of them. Having less but important features is not only to be considered as \"nice to have\" but really an important step to tuning algorithm performance.\n",
    "\n",
    "One way to perform feature selection is to query the feature importances for a classifier and then modifiy the features list manually to exlude the ones below a certain threshold. In the following I will query the feature importances at the example of DecisionTreeClassifier and AdaBoostClassifier. For each I will print a features list ordered by importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "\tAccuracy: 0.89620\tPrecision: 0.61159\tRecall: 0.60700\tF1: 0.60928\tF2: 0.60791\n",
      "\tTotal predictions: 15000\tTrue positives: 1214\tFalse positives:  771\tFalse negatives:  786\tTrue negatives: 12229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_tree = DecisionTreeClassifier()\n",
    "tester.test_classifier(clf_tree, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Feature Importances:\n",
      "\n",
      "from_poi_ratio : 0.3521\n",
      "shared_receipt_with_poi : 0.2094\n",
      "other : 0.1693\n",
      "expenses : 0.1469\n",
      "to_poi_ratio : 0.0688\n",
      "from_messages : 0.0535\n",
      "salary : 0.0000\n",
      "bonus : 0.0000\n",
      "long_term_incentive : 0.0000\n",
      "deferred_income : 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Get the feature importances of the DecisionTree Classifier\n",
    "tree_feature_importances = (clf_tree.feature_importances_)\n",
    "tree_features = zip(tree_feature_importances, features_list[1:])\n",
    "tree_features = sorted(tree_features, key= lambda x:x[0], reverse=True)\n",
    "\n",
    "# Display the feature names with 10 highest importance values\n",
    "print('Tree Feature Importances:\\n')\n",
    "for i in range(10):\n",
    "    print('{} : {:.4f}'.format(tree_features[i][1], tree_features[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "\tAccuracy: 0.88013\tPrecision: 0.56114\tRecall: 0.46350\tF1: 0.50767\tF2: 0.48021\n",
      "\tTotal predictions: 15000\tTrue positives:  927\tFalse positives:  725\tFalse negatives: 1073\tTrue negatives: 12275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_ada = AdaBoostClassifier()\n",
    "tester.test_classifier(clf_ada, my_dataset, features_list);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada Boost Feature Importances:\n",
      "\n",
      "total_payments : 0.1400\n",
      "to_poi_ratio : 0.1400\n",
      "exercised_stock_options : 0.1200\n",
      "other : 0.1000\n",
      "from_this_person_to_poi : 0.1000\n",
      "shared_receipt_with_poi : 0.0800\n",
      "expenses : 0.0600\n",
      "from_poi_to_this_person : 0.0600\n",
      "from_poi_ratio : 0.0600\n",
      "deferred_income : 0.0400\n"
     ]
    }
   ],
   "source": [
    "# Get the feature importances for the AdaBoost Classifier\n",
    "ada_feature_importances = clf_ada.feature_importances_\n",
    "ada_features = zip(ada_feature_importances, features_list[1:])\n",
    "\n",
    "# Display the feature names with 10 highest importance values\n",
    "print('Ada Boost Feature Importances:\\n')\n",
    "ada_features = sorted(ada_features, key=lambda x:x[0], reverse=True)\n",
    "for i in range(10):\n",
    "    print('{} : {:.4f}'.format(ada_features[i][1], ada_features[i][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting observation is that the top 10 features do not really conform. So feature importances can vary quite considerably between different algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "When it comes to evaluate an algorithm, there are several evaluation metrics at our disposal, as seen during the whole project. Each of them is a perfectly valid means for evaluation but also typcially favors one type of error which is why we should use different metrics if we want our classifier to be able to generalize on the data.\n",
    "\n",
    "#### Accuracy\n",
    "\n",
    "It describes the ratio between the items labeled correctly and all items. In the Enron case, the ratio between correctly identified POIs and all persons.\n",
    "The difficulty we face in the Enron data is that there are many more non-POIs than POI. This poses the problem that one could simply assign the more common label for all data points and still reach a pretty high Accuracy.\n",
    "\n",
    "#### Recall\n",
    "Recall is intuitively the ability of the classifier to find all the positive samples. In the Enron case, Recall describes the ability of the algorithm to correctly identify a POI provided that the person is a POI. Boosting the Recall metric has the affect that the classifier is correctly identifying every single POI. The tradeoff is that the algorithm will be biased towards identifying POIs. In this case this is rather what we want - better make sure no POI gues unnoticed and later declare the misclassified individuals innocent.\n",
    "\n",
    "#### Precision\n",
    "Intuitively, precision is the ability of the classifier not to label as positive a sample that is negative. In the Enron case, if the classifier doesn't have great Recall, but it does have good Precision, it means that whenever a POI gets flagged in the test set, there is good confidence that it is a real POI and not a false alarm. The tradeoff is that sometimes real POIs are missed, which in the case of Enron is definitely something we do not want.\n",
    "\n",
    "#### F1-Score\n",
    "The F1 score can be interpreted as a weighted average of the precision and recall. The relative contribution of precision and recall to the F1 score are equal. In some way, the F1 score can be thought of \"the best of both worlds\". It will probably serve as a good metric for most problems and deliver a relatively balanced model. In the Enron case, I would argue that actually a good Recall is more important even at the cost of a lower Precision. But for the purpose of this project I think that optimizing on the F1-score should serve me well. This is accounted for in the code by \"scoring='f1'\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV with SelectKBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another means for feature selection is to use SelectKBest which removes all but the k highest scoring features. Only the problem is that we don't yet know the value of k, i.e. the optimal number of features. I could manually play around with k until I assume having found the optimal number but there is a better way...\n",
    "\n",
    "Namely, what I can do is to combine SelektKBest with GridSearchCV in order to identify the highest scoring features and at the same time find the optimal number of features. To combine these two functions one can use another tool called Pipeline. Pipeline can be used to chain multiple estimators into one. This is useful as there is often a fixed sequence of steps in processing the data, for example in feature selection. Using a pipeline one can perform a Grid Search over parameters of all estimators in the pipeline at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data with feature_format.py\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "data_dict = featureFormat(my_dataset, features_list)\n",
    "labels, features = targetFeatureSplit(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_scaled = featureFormat(my_dataset_scaled, features_list)\n",
    "labels_scaled, features_scaled = targetFeatureSplit(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I do not want to use the tester.py script like I did before but still need to split my data in labels and features, I can use the *featureFormat*- as well as *targetFeatureSplit*-fuctions from the feature_format.py script to format and split the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search with SelektKBest for DecisionTreeClassifier\n",
    "The pipeline can be used like any other estimator and avoids leaking the test set into the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# Create a pipeline with feature selection and classification\n",
    "estimators = [\n",
    "    ('select_features', SelectKBest()),\n",
    "    ('classify', DecisionTreeClassifier())\n",
    "]\n",
    "\n",
    "n_features = np.arange(1, len(features_list))\n",
    "\n",
    "param_grid = [{'select_features__k': n_features}]\n",
    "\n",
    "pipe = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rapha\\anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('select_features', SelectKBest(k=10, score_func=<function f_classif at 0x000000000C4FB5F8>)), ('classify', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'select_features__k': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_tree = GridSearchCV(pipe, param_grid=param_grid, scoring='f1', cv = 10)\n",
    "grid_search_tree.fit(features_scaled, labels_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select_features__k': 18}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_tree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67245370370370372"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_tree.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GridSearch with SelectKBest states that the optimal number of features for the DecisionTreeClassifier is 18 out of 24 that we have at our disposal. The corresponding score that was achieved with the 18 best features is not too bad either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomized Search with SelektKBest for DecisionTreeClassifier\n",
    "When tuning the hyperparameters of an estimator, Grid Search and Random Search are both popular methods. According to some publications random search is even perceived as the better method depending on the type of problem. That is why I wanted to see how it performs in direct comparison although the requirement for this project is to use GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {'select_features__k': n_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=Pipeline(steps=[('select_features', SelectKBest(k=10, score_func=<function f_classif at 0x000000000C4FB5F8>)), ('classify', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'))]),\n",
       "          fit_params={}, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'select_features__k': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23])},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_tree = RandomizedSearchCV(pipe, param_dist, scoring='f1', cv = 10)\n",
    "random_search_tree.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select_features__k': 21}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_tree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65509259259259267"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_tree.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomSearch returns a k-value of 21 resulting in a lower F1-score than with the 18 features that GridSearch identified as best. So in this case GridSearch returns a better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search with SelektKBest for AdaBoost Classifier\n",
    "Same as we just did for DecisionTree now for AdaBosst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with feature selection and classification for AdaBoost\n",
    "estimators = [\n",
    "    ('select_features', SelectKBest()),\n",
    "    ('classify', AdaBoostClassifier())\n",
    "]\n",
    "\n",
    "n_features = np.arange(1, len(features_list))\n",
    "\n",
    "param_grid = [{'select_features__k': n_features}]\n",
    "\n",
    "pipe = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('select_features', SelectKBest(k=10, score_func=<function f_classif at 0x000000000C4FB5F8>)), ('classify', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'select_features__k': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_ada = GridSearchCV(pipe, param_grid=param_grid, scoring='f1', cv =10)\n",
    "grid_search_ada.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select_features__k': 16}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_ada.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62152777777777779"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_ada.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomized Search with SelectKBest for AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {'select_features__k': n_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=Pipeline(steps=[('select_features', SelectKBest(k=10, score_func=<function f_classif at 0x000000000C4FB5F8>)), ('classify', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None))]),\n",
       "          fit_params={}, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'select_features__k': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23])},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_ada = RandomizedSearchCV(pipe, param_dist, scoring='f1', cv = 10)\n",
    "random_search_ada.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select_features__k': 16}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_ada.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62152777777777779"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_ada.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For AdaBoost however GridSearchCV and RandomSearch deliver the same results. The optimal number of features found by SelectKBest for the AdaBoostClassifier is 16. \n",
    "\n",
    "For the following RandomForest and GaussianNB I will be running SelectKBest in combination with GridSearch since this is actually the requirement for this project and in the previous cases performed best, or at least equally well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search with SelektKBest for RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('select_features', SelectKBest()),\n",
    "    ('classify', RandomForestClassifier())\n",
    "]\n",
    "\n",
    "n_features = np.arange(1, len(features_list))\n",
    "\n",
    "param_grid = [{'select_features__k': n_features}]\n",
    "\n",
    "pipe = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('select_features', SelectKBest(k=10, score_func=<function f_classif at 0x000000000C4FB5F8>)), ('classify', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impu...mators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'select_features__k': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf = GridSearchCV(pipe, param_grid=param_grid, scoring='f1', cv =10)\n",
    "grid_search_rf.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select_features__k': 6}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53356481481481477"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the GridSearch of the RandomForestClassifier I chose to apply scaling since I want to use scaled data also for the final testing. For Random Forest the optimal number of features is 21."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search with SelektKBest for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('select_features', SelectKBest(k=10, score_func=<function f_classif at 0x000000000C4FB5F8>)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classify', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'select_features__k': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pipeline with feature selection and classification for SVC\n",
    "\n",
    "estimators = [\n",
    "    ('select_features', SelectKBest()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classify', SVC()),\n",
    "]\n",
    "\n",
    "n_features = np.arange(1, len(features_list))\n",
    "\n",
    "param_grid = [{'select_features__k': n_features}]\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "grid_search_svc = GridSearchCV(pipe, param_grid=param_grid, scoring='f1', cv =10)\n",
    "grid_search_svc.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select_features__k': 3}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13425925925925924"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_svc.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately using SelectKBest on SVC did not return a valid result. At least for me 3 features do not really make sense. Therefore I will not do feature selection and run the final classifier with the complete set of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search with SelektKBest for GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('select_features', SelectKBest(k=10, score_func=<function f_classif at 0x000000000C4FB5F8>)), ('classify', GaussianNB(priors=None))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'select_features__k': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pipeline with feature selection and classification for SVC\n",
    "\n",
    "estimators = [\n",
    "    ('select_features', SelectKBest()),\n",
    "    ('classify', GaussianNB()),\n",
    "]\n",
    "\n",
    "n_features = np.arange(1, len(features_list))\n",
    "\n",
    "param_grid = [{'select_features__k': n_features}]\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "grid_search_gnb = GridSearchCV(pipe, param_grid=param_grid, scoring='f1', cv =10)\n",
    "grid_search_gnb.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select_features__k': 22}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_gnb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37638888888888888"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_gnb.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For GaussionNB the optimal number of features is 22."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the classifiers with optimal number of features\n",
    "Now that I know the optimal number of features for each individual classifier I want to test the classifiers with their respective best number of features using the tester.py script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('select_features', SelectKBest(k=18, score_func=<function f_classif at 0x000000000C4FB5F8>)), ('classify', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'))])\n",
      "\tAccuracy: 0.89927\tPrecision: 0.62367\tRecall: 0.61650\tF1: 0.62007\tF2: 0.61792\n",
      "\tTotal predictions: 15000\tTrue positives: 1233\tFalse positives:  744\tFalse negatives:  767\tTrue negatives: 12256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the classifier with the optimal hyperparameters as found by GridSearchCV\n",
    "tree_clf_kbest = Pipeline([\n",
    "    ('select_features', SelectKBest(k=18)),\n",
    "    ('classify', DecisionTreeClassifier()),\n",
    "])\n",
    "# Test the classifier using tester.py\n",
    "tester.dump_classifier_and_data(tree_clf_kbest, my_dataset, features_list)\n",
    "tester.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the DecisionTree again I took the unscaled data. I tried both but the unscaled yielded a higher performance here even though in the out-of-the-box run it performed better with the scaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('select_features', SelectKBest(k=16, score_func=<function f_classif at 0x000000000C4FB5F8>)), ('classify', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None))])\n",
      "\tAccuracy: 0.88927\tPrecision: 0.60180\tRecall: 0.50100\tF1: 0.54679\tF2: 0.51837\n",
      "\tTotal predictions: 15000\tTrue positives: 1002\tFalse positives:  663\tFalse negatives:  998\tTrue negatives: 12337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the classifier with the optimal hyperparameters as found by GridSearchCV\n",
    "ada_clf_kbest = Pipeline([\n",
    "    ('select_features', SelectKBest(k=16)),\n",
    "    ('classify', AdaBoostClassifier()),\n",
    "])\n",
    "# Test the classifier using tester.py\n",
    "tester.dump_classifier_and_data(ada_clf_kbest, my_dataset, features_list)\n",
    "tester.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('select_features', SelectKBest(k=6, score_func=<function f_classif at 0x000000000C4FB5F8>)), ('classify', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      "\tAccuracy: 0.86853\tPrecision: 0.51333\tRecall: 0.26950\tF1: 0.35344\tF2: 0.29779\n",
      "\tTotal predictions: 15000\tTrue positives:  539\tFalse positives:  511\tFalse negatives: 1461\tTrue negatives: 12489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the classifier with the optimal hyperparameters as found by GridSearchCV\n",
    "rf_clf_kbest = Pipeline([\n",
    "    ('select_features', SelectKBest(k=6)),\n",
    "    ('classify', RandomForestClassifier()),\n",
    "])\n",
    "# Test the classifier using tester.py\n",
    "tester.dump_classifier_and_data(rf_clf_kbest, my_dataset, features_list)\n",
    "tester.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('select_features', SelectKBest(k=22, score_func=<function f_classif at 0x000000000C4FB5F8>)), ('classify', GaussianNB(priors=None))])\n",
      "\tAccuracy: 0.77707\tPrecision: 0.26569\tRecall: 0.38100\tF1: 0.31306\tF2: 0.35057\n",
      "\tTotal predictions: 15000\tTrue positives:  762\tFalse positives: 2106\tFalse negatives: 1238\tTrue negatives: 10894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the classifier with the optimal hyperparameters as found by GridSearchCV\n",
    "gnb_clf_kbest = Pipeline([\n",
    "    ('select_features', SelectKBest(k=22)),\n",
    "    ('classify', GaussianNB()),\n",
    "])\n",
    "# Test the classifier using tester.py\n",
    "tester.dump_classifier_and_data(gnb_clf_kbest, my_dataset, features_list)\n",
    "tester.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "https://en.wikipedia.org/wiki/Hyperparameter_optimization\n",
    "\n",
    "In machine learning, hyperparameter optimization or tuning is the problem of choosing a set of optimal hyperparameters for a learning algorithm. A hyperparameter is a parameter whose value is used to control the learning process. The same kind of machine learning model can require different constraints, weights or learning rates to generalize different data patterns. These measures are called hyperparameters, and have to be tuned so that the model can optimally solve the machine learning problem.Cross-validation is often used to estimate this generalization performance.\n",
    "The traditional way of performing hyperparameter optimization is grid search or randomized search. Grid search is simply an exhaustive searching through a manually specified subset of the hyperparameter space of a learning algorithm. A grid search algorithm must be guided by some performance metric, typically measured by cross-validation on the training set or evaluation on a held-out validation set.\n",
    "Random Search replaces the exhaustive enumeration of all combinations by selecting them randomly. It can outperform Grid search, especially when only a small number of hyperparameters affects the final performance of the machine learning algorithm.\n",
    "\n",
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('select_features', SelectKBest(k=18, score_func=<function f_classif at 0x000000000C4FB5F8>)), ('classify', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'classify__splitter': ['best', 'random'], 'classify__criterion': ['gini', 'entropy'], 'classify__min_samples_split': [2, 4, 6, 8, 10, 20, 40], 'classify__max_depth': [None, 5, 10, 15, 20], 'classify__max_features': [None, 'sqrt', 'log2', 'auto'], 'classify__min_samples_leaf': [2, 4, 6, 8, 10, 20, 40]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pipeline with feature selection and classifier\n",
    "\n",
    "tree_pipe = Pipeline([\n",
    "    ('select_features', SelectKBest(k=18)),\n",
    "    ('classify', DecisionTreeClassifier()),\n",
    "])\n",
    "\n",
    "# Define the configuration of parameters to test with the \n",
    "# Decision Tree Classifier\n",
    "param_grid = dict(classify__criterion = ['gini', 'entropy'],\n",
    "                  classify__splitter = ['best', 'random'],\n",
    "                  classify__max_depth = [None, 5, 10, 15, 20],\n",
    "                  classify__min_samples_split = [2, 4, 6, 8, 10, 20, 40],\n",
    "                  classify__min_samples_leaf = [2, 4, 6, 8, 10, 20, 40],\n",
    "                  classify__max_features = [None, 'sqrt', 'log2', 'auto'])\n",
    "\n",
    "# Use GridSearchCV to find the optimal hyperparameters for the classifier\n",
    "tree_clf_tuned = GridSearchCV(tree_pipe, param_grid = param_grid, scoring='f1', cv=10)\n",
    "tree_clf_tuned.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7592592592592593"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf_tuned.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classify__criterion': 'entropy',\n",
       " 'classify__max_depth': None,\n",
       " 'classify__max_features': None,\n",
       " 'classify__min_samples_leaf': 2,\n",
       " 'classify__min_samples_split': 20,\n",
       " 'classify__splitter': 'best'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf_tuned.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rapha\\anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\naive_bayes.py:232: RuntimeWarning: invalid value encountered in divide\n",
      "  new_mu = np.average(X, axis=0, weights=sample_weight / n_new)\n",
      "C:\\Users\\Rapha\\anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\naive_bayes.py:234: RuntimeWarning: invalid value encountered in divide\n",
      "  weights=sample_weight / n_new)\n",
      "C:\\Users\\Rapha\\anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\naive_bayes.py:427: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "C:\\Users\\Rapha\\anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:288: RuntimeWarning: invalid value encountered in less\n",
      "  proba[proba < np.finfo(proba.dtype).eps] = np.finfo(proba.dtype).eps\n",
      "C:\\Users\\Rapha\\anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:603: RuntimeWarning: invalid value encountered in greater\n",
      "  return self.classes_.take(pred > 0, axis=0)\n",
      "C:\\Users\\Rapha\\anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:519: RuntimeWarning: invalid value encountered in less\n",
      "  proba[proba < np.finfo(proba.dtype).eps] = np.finfo(proba.dtype).eps\n",
      "C:\\Users\\Rapha\\anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:531: RuntimeWarning: invalid value encountered in less\n",
      "  (estimator_weight < 0)))\n",
      "C:\\Users\\Rapha\\anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:530: RuntimeWarning: invalid value encountered in greater\n",
      "  ((sample_weight > 0) |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('select_features', SelectKBest(k=16, score_func=<function f_classif at 0x000000000C4FB5F8>)), ('classify', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'classify__learning_rate': [0.5, 1, 1.5, 2, 4], 'classify__n_estimators': [50, 100, 150, 200], 'classify__base_estimator': [DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07..._score=False, random_state=None,\n",
       "            verbose=0, warm_start=False), GaussianNB(priors=None)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create the pipeline with feature selection and AdaBoostClassifier\n",
    "ada_pipe = Pipeline([('select_features', SelectKBest(k=16)),\n",
    "                     ('classify', AdaBoostClassifier())\n",
    "                    ])\n",
    "\n",
    "# Define the parameter configurations to test with GridSearchCV\n",
    "param_grid = dict(classify__base_estimator=[DecisionTreeClassifier(), RandomForestClassifier(), GaussianNB()],\n",
    "                  classify__n_estimators = [50, 100, 150, 200],\n",
    "                  classify__learning_rate = [0.5, 1, 1.5, 2, 4])\n",
    "\n",
    "# Use GridSearchCV to automate the process of finding the optimal parameters\n",
    "ada_clf_tuned = GridSearchCV(ada_pipe, param_grid=param_grid, scoring='f1', cv=10)\n",
    "ada_clf_tuned.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66435185185185186"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf_tuned.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classify__base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             presort=False, random_state=None, splitter='best'),\n",
       " 'classify__learning_rate': 4,\n",
       " 'classify__n_estimators': 200}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf_tuned.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('select_features', SelectKBest(k=6, score_func=<function f_classif at 0x000000000C4FB5F8>)), ('classify', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impur...mators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'classify__n_estimators': [5, 10, 50, 100, 200], 'classify__criterion': ['gini', 'entropy'], 'classify__max_depth': [None, 4, 5, 6, 7, 8]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pipeline with feature selection and classifier\n",
    "rf_pipe = Pipeline([\n",
    "    ('select_features', SelectKBest(k=6)),\n",
    "    ('classify', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "# Define the configuration of parameters to test with the \n",
    "# Random Forest Classifier\n",
    "param_grid = dict(classify__n_estimators = [5, 10, 50, 100, 200],\n",
    "                  classify__criterion = ['gini', 'entropy'],\n",
    "                  classify__max_depth = [None, 4, 5, 6, 7, 8],\n",
    "#                  classify__min_samples_split = [2, 4, 6, 8, 10, 20],\n",
    "#                  classify__min_samples_leaf = [2, 4, 6, 8, 10, 20],\n",
    "#                  classify__max_features = [None, 'sqrt', 'log2', 'auto']\n",
    "                 )\n",
    "\n",
    "# Use GridSearchCV to find the optimal hyperparameters for the classifier\n",
    "rf_clf_tuned = GridSearchCV(rf_pipe, param_grid = param_grid, scoring='f1', cv=10)\n",
    "rf_clf_tuned.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51851851851851849"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf_tuned.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classify__criterion': 'entropy',\n",
       " 'classify__max_depth': 6,\n",
       " 'classify__n_estimators': 10}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf_tuned.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest comes with a bunch of parameters. I opted for *'criterion', 'max_depth', 'n_estimator'*. When I select more than that(like the ones that are commented out in above code) the process would take unreasonably long or would not terminate at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rapha\\anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\svm\\base.py:220: ConvergenceWarning: Solver terminated early (max_iter=1).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Rapha\\anaconda3\\envs\\python2\\lib\\site-packages\\sklearn\\svm\\base.py:220: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classify', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'classify__C': [1, 50, 100, 1000], 'classify__degree': [1, 2], 'classify__max_iter': [1, 100, 1000], 'classify__gamma': [0.5, 0.1, 0.01], 'classify__kernel': ['rbf', 'poly', 'linear']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using scaling on SVC-classifier since I already saw in chapter \"Scaling\" that it tends to improve performance on SVC\n",
    "# Create a pipeline with feature selection and classifier\n",
    "svm_pipe = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classify', SVC()),\n",
    "])\n",
    "\n",
    "# Define the configuration of parameters to test with the SVC Classifier\n",
    "param_grid = ([{'classify__C': [1, 50, 100, 1000],\n",
    "                'classify__gamma': [0.5, 0.1, 0.01],\n",
    "                'classify__degree': [1, 2],\n",
    "                'classify__kernel': ['rbf', 'poly', 'linear'],\n",
    "                'classify__max_iter': [1, 100, 1000]}])\n",
    "\n",
    "# Use GridSearchCV to find the optimal hyperparameters for the classifier\n",
    "svm_clf_tuned = GridSearchCV(svm_pipe, param_grid = param_grid, scoring='f1', cv=10)\n",
    "svm_clf_tuned.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57407407407407396"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf_tuned.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classify__C': 1000,\n",
       " 'classify__degree': 1,\n",
       " 'classify__gamma': 0.01,\n",
       " 'classify__kernel': 'rbf',\n",
       " 'classify__max_iter': 100}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf_tuned.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GaussianNB\n",
    "\n",
    "For GaussianNB there are no hyperparameters avaiable to tune."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a summary of the hyperparameters obtained from GridSearch and SelectKBest:\n",
    "\n",
    "__Decision Tree Classifier__:\n",
    "\n",
    "| Parameter         | SelectKBest | criterion | max_depth | max_features | min\\_samples\\_split | min\\_samples\\_leaf | splitter |\n",
    "|------------------ |-------------|-----------|-----------|--------------|---------------------|--------------------|----------|\n",
    "| __Optimal Value__ |      18     | 'entropy' |    None   |     None     |          20         |          2         |   best   |\n",
    "\n",
    "__AdaBoost Classifier__:\n",
    "\n",
    "| Parameter         | SelectKBest | base\\_estimator        | learning\\_rate | n\\_estimators |\n",
    "|-------------------|-------------|------------------------|----------------|---------------|\n",
    "| __Optimal Value__ |      16     | DecisionTreeClassifier |       4        |      200      |\n",
    "\n",
    "__Random Forest Classifier__:\n",
    "\n",
    "| Parameter         | SelectKBest | criterion | max_depth | n_estimators |\n",
    "|------------------ |-------------|-----------|-----------|--------------|\n",
    "| __Optimal Value__ |      6      | 'entropy' |     6     |      10      |\n",
    "\n",
    "__SVC Classifier__:\n",
    "\n",
    "| Parameter         |  'C' | degree | gamma | kernel | max\\_iter |\n",
    "|-------------------|------|--------|-------|--------|-----------|\n",
    "| __Optimal Value__ | 1000 |    1   |  0.01 |   rbf  |     100   |\n",
    "\n",
    "__Gaussian Naive Bayes__:\n",
    "\n",
    "| Parameter         | SelectKBest |\n",
    "|-------------------|-------------|\n",
    "| __Optimal Value__ |      22     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Test\n",
    "The final step is to implement the optimal hyper parameters into the models and to finally test the classifiers with that configuration using the provided tester function.\n",
    "\n",
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('select_features', SelectKBest(k=18, score_func=<function f_classif at 0x000000000C4FB5F8>)), ('classify', DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=2,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'))])\n",
      "\tAccuracy: 0.92333\tPrecision: 0.68398\tRecall: 0.79000\tF1: 0.73318\tF2: 0.76625\n",
      "\tTotal predictions: 15000\tTrue positives: 1580\tFalse positives:  730\tFalse negatives:  420\tTrue negatives: 12270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tester.dump_classifier_and_data(tree_clf_tuned.best_estimator_, my_dataset, features_list)\n",
    "tester.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Check: In above cell I queried the results from the DecisionTreeClassifier with the optimal parameters found by grid search using \".best_estimator_\". As a cross check I will again build a classifier manually with these exact parameters. The results should be identical. And indeed they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('select_features', SelectKBest(k=18, score_func=<function f_classif at 0x000000000C4FB5F8>)), ('classify', DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=2,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'))])\n",
      "\tAccuracy: 0.92240\tPrecision: 0.68017\tRecall: 0.78900\tF1: 0.73056\tF2: 0.76453\n",
      "\tTotal predictions: 15000\tTrue positives: 1578\tFalse positives:  742\tFalse negatives:  422\tTrue negatives: 12258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Implement the Decision Tree Classifier with the optimal parameters\n",
    "tree_clf_final = Pipeline([\n",
    "    ('select_features', SelectKBest(k=18)),\n",
    "    ('classify', DecisionTreeClassifier(criterion='entropy', splitter='best' ,max_depth=None, max_features=None, min_samples_leaf=2, min_samples_split=20))\n",
    "])\n",
    "\n",
    "# Test the classifier with cross-validation\n",
    "tester.dump_classifier_and_data(tree_clf_final, my_dataset, features_list)\n",
    "tester.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('select_features', SelectKBest(k=16, score_func=<function f_classif at 0x000000000C4FB5F8>)), ('classify', AdaBoostClassifier(algorithm='SAMME.R',\n",
      "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_node...ndom_state=None, splitter='best'),\n",
      "          learning_rate=4, n_estimators=200, random_state=None))])\n",
      "\tAccuracy: 0.89887\tPrecision: 0.62391\tRecall: 0.60800\tF1: 0.61585\tF2: 0.61112\n",
      "\tTotal predictions: 15000\tTrue positives: 1216\tFalse positives:  733\tFalse negatives:  784\tTrue negatives: 12267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the classifier with cross-validation\n",
    "tester.dump_classifier_and_data(ada_clf_tuned.best_estimator_, my_dataset, features_list)\n",
    "tester.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('select_features', SelectKBest(k=6, score_func=<function f_classif at 0x000000000C4FB5F8>)), ('classify', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=6, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      "\tAccuracy: 0.86600\tPrecision: 0.49545\tRecall: 0.27200\tF1: 0.35119\tF2: 0.29897\n",
      "\tTotal predictions: 15000\tTrue positives:  544\tFalse positives:  554\tFalse negatives: 1456\tTrue negatives: 12446\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tester.dump_classifier_and_data(rf_clf_tuned.best_estimator_, my_dataset, features_list)\n",
    "tester.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classify', SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=1, gamma=0.01, kernel='rbf',\n",
      "  max_iter=100, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "\tAccuracy: 0.89020\tPrecision: 0.60376\tRecall: 0.51350\tF1: 0.55499\tF2: 0.52933\n",
      "\tTotal predictions: 15000\tTrue positives: 1027\tFalse positives:  674\tFalse negatives:  973\tTrue negatives: 12326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tester.dump_classifier_and_data(svm_clf_tuned.best_estimator_, my_dataset, features_list)\n",
    "tester.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of the SVC I applied standard scaling since SVMs require standardized data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GaussianNB\n",
    "\n",
    "No parameter tuning performed. Hence, same results as in chapter \"Testing the classifiers with optimal number of features\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('select_features', SelectKBest(k=22, score_func=<function f_classif at 0x000000000C4FB5F8>)), ('classify', GaussianNB(priors=None))])\n",
      "\tAccuracy: 0.77707\tPrecision: 0.26569\tRecall: 0.38100\tF1: 0.31306\tF2: 0.35057\n",
      "\tTotal predictions: 15000\tTrue positives:  762\tFalse positives: 2106\tFalse negatives: 1238\tTrue negatives: 10894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tester.dump_classifier_and_data(gnb_clf_kbest, my_dataset, features_list)\n",
    "tester.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last here is a summary of my final results:\n",
    "\n",
    "| Algorithm    | Accuracy | Precision | Recall | F1 Score |\n",
    "|--------------|----------|-----------|--------|----------|\n",
    "| DecisionTree | 0.923    | 0.684     | 0.790  | 0.733    |\n",
    "| AdaBoost     | 0.899    | 0.624     | 0.608  | 0.616    |\n",
    "| RandomForest | 0.866    | 0.495     | 0.272  | 0.351    |\n",
    "| SVC          | 0.890    | 0.604     | 0.514  | 0.555    |\n",
    "| GaussianNB   | 0.777    | 0.266     | 0.381  | 0.313    |\n",
    "\n",
    "The best performing algorithm is pretty clearly the DecisionTreeClassifier. No huge surprise though, since it has already ranged among the best algorithms in the out-of-the-box runs. So if I were to build up a model to identify POIs with machine learning the DecisionTreeClassifier would be the algorithm of my choice. \n",
    "\n",
    "The weakest performance delivered GaussianNB and RandomForest not even reaching the minimum requirements of this project of 0.3 for precision respectively recall. GaussianNB did not perform too bad in the initial runs but due to the fact that it does not come with any hyperparameter tuning options I was not able to enhance the performance. RandomForest is said to be a very powerful ensemble-algorithm, which is why I did not want to give up on it until the very end hoping that hyperparameter tuning would have a significant effect, but unfortunately not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In the process of the project I happened to mix up the terms 'Overfitting' and 'Data Leakage'. Maybe because I didn't fully understand the difference. I thought all of this is kind of what is being referred to as 'Overfitting'. Maybe because both classic overfitting and data leakage will result in a model performing well on training data but poorly on unseen 'real world' data. But nevertheless I think one needs to distinguish between the two. \n",
    "\n",
    "Overfitting is a complex issue of which every aspiring machine learner should be aware. That is why I want to dedicate my conclusion to this topic.\n",
    "\n",
    "#### What is Overfitting?\n",
    "In order to evaluate the performance of a particular ML model, we invariably split the data into two sets including training and testing subsets. The algorithm is trained on the training dataset and evaluated/tested on the test dataset, then it is applied to make predictions on new (unseen) data points. Overfitting occurs when the model performs too well on the training data but poorly on the new data points while the goal is to maximize its accuracy on the unseen data points. This means that the model fails to generalize to unseen data.\n",
    "\n",
    "I would describe classic overfitting at following example:\n",
    "\n",
    "For example, in its fundamental nature, an SVC classifier works by recursively drawing a boundary between different classes on the data, that maximizes the distance to the nearest point, also called the margin.\n",
    "\n",
    "On the one hand this boundary can be as simplistic as a straight line, which generalizes well but doesn't yield optimal results out of a particular situation. On the other hand it can be a twisted, wiggled boundary with an exceptional fit for that situation, but it wouldn't fit other situations. In this case our classifier would be somehow biased by the data and that's a clear example of overfitting. \n",
    "\n",
    "To avoid such an overfit situation but still yield a good performance we have to find the optimal hyperparameters. This can for example be done using GridSearch or Random Search, as we did in our project.\n",
    "\n",
    "#### How to avoid Overfitting:\n",
    "\n",
    "Source: https://elitedatascience.com/overfitting-in-machine-learning\n",
    "\n",
    "1. Perform Cross Validation\n",
    "2. Train with more data\n",
    "3. Remove features\n",
    "4. Early stopping\n",
    "5. Regularization\n",
    "6. Ensembling\n",
    "\n",
    "#### What is Data Leakage?\n",
    "When the data you are using to train a machine learning algorithm happens to have the information you are trying to predict.\n",
    "\n",
    "#### Overfitting vs. Data Leakage\n",
    "When data leakage occurs, it may lead to overfitting (overly optimistic training accuracy) but the model also performs too well on the test data. As we mentioned, data points are leaked from test set into training set, which means the model will predict something it learned/saw (but we think it is unseen data points) while overfitting may lead to poor generalization performance of a predictive model.\n",
    "\n",
    "#### How to avoid Data Leackage:\n",
    "\n",
    "Source: https://machinelearningmastery.com/data-leakage-machine-learning/\n",
    "\n",
    "1. Perform data preparation within cross validation folds\n",
    "2. Hold back a validation dataset\n",
    "\n",
    "Generally, it is good practice to use both of these techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Perform Data Preparation Within Cross Validation Folds\n",
    "You can easily leak information when preparing your data for machine learning. The effect is overfitting your training data and having an overly optimistic evaluation of your models performance on unseen data. For example, if you normalize or standardize your entire dataset, then estimate the performance of your model using cross validation, you have committed the sin of data leakage.The data rescaling process that you performed had knowledge of the full distribution of data in the training dataset when calculating the scaling factors (like min and max or mean and standard deviation). This knowledge was stamped into the rescaled values and exploited by all algorithms in your cross validation test harness. A non-leaky evaluation of machine learning algorithms in this situation would calculate the parameters for rescaling data within each fold of the cross validation and use those parameters to prepare the data on the held out test fold on each cycle.\n",
    "\n",
    "2. Hold Back a Validation Dataset\n",
    "Another, perhaps simpler approach is to split your training dataset into train and validation sets, and store away the validation dataset. Once you have completed your modeling process and actually created your final model, evaluate it on the validation dataset. This can give you a sanity check to see if your estimation of performance has been overly optimistic and has leaked."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
